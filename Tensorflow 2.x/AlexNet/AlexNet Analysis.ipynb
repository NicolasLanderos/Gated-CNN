{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fZOMjk-2pGPs"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading CIFAR10 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "feuqKVkHqQVW"
   },
   "outputs": [],
   "source": [
    "(_, _), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "# Reducing Target innecessary dimension\n",
    "y_test  = np.squeeze(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dataset Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9YPFldhqV5K"
   },
   "outputs": [],
   "source": [
    "# Normalize Images\n",
    "def normalize_img(x_, y_):\n",
    "    return tf.cast(x_, tf.float32) / 255., y_\n",
    "\n",
    "# 1-hot encoding\n",
    "def to_categorical(x_, y_):\n",
    "    return x_, tf.one_hot(y_, depth=10)\n",
    "\n",
    "# Resizing \n",
    "def process_images(image, label):\n",
    "    # Resize images from 32x32 to 277x277\n",
    "    image = tf.image.resize(image, (227,227))\n",
    "    return image, label\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.map(normalize_img)\n",
    "test_dataset = test_dataset.map(to_categorical)\n",
    "test_dataset = test_dataset.map(process_images)\n",
    "test_dataset = test_dataset.batch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Quantization_layer(tensor, Quantization = True,signed = True, word_size = 12, frac_size = 6):\n",
    "    \n",
    "    factor = 2.0**frac_size\n",
    "    \n",
    "    # Quantized max and min values, in case of the need to implement overflow cases.\n",
    "    #if signed:\n",
    "    #    Max_Qvalue = ((1 << (word_size-1)) - 1)/factor\n",
    "    #    Min_Qvalue = -Max_Qvalue - 1\n",
    "    #else:\n",
    "    #    Max_Qvalue = ((1 << (word_size)) - 1)/factor\n",
    "    #    Min_Qvalue = 0\n",
    "    \n",
    "    if Quantization:\n",
    "        return tf.round(tensor*factor) / factor             #Quantization, assuming no overflow\n",
    "    else:\n",
    "        return tensor                                       #Simple Bypass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvho0zVa0Oti"
   },
   "source": [
    "## Creating AlexNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Dense, BatchNormalization, MaxPool2D, Flatten, Dropout, Lambda\n",
    "\n",
    "\n",
    "def build_model(input_layer, Quantization = True, signed = True, word_size = 12, frac_size = 6 ):\n",
    "    \n",
    "    Arguments = {'Quantization':Quantization, 'signed':signed, 'word_size':word_size, 'frac_size':frac_size}\n",
    "    QInp      = Lambda(Quantization_layer, arguments = Arguments )(input_layer)\n",
    "    \n",
    "    #Conv Block\n",
    "    Conv1   = Conv2D(filters=96, kernel_size=(11,11), strides=(4,4))(QInp)\n",
    "    QConv1  = Lambda(Quantization_layer, arguments = Arguments )(Conv1)\n",
    "    Relu1   = tf.keras.activations.relu(QConv1)\n",
    "    QRelu1  = Lambda(Quantization_layer, arguments = Arguments )(Relu1)\n",
    "    BN1     = BatchNormalization()(QRelu1)\n",
    "    QBN1    = Lambda(Quantization_layer, arguments = Arguments )(BN1)\n",
    "    MP1     = MaxPool2D(pool_size=(3,3), strides=(2,2))(QBN1)\n",
    "    \n",
    "    Conv2   = Conv2D(filters=256, kernel_size=(5,5), strides=(1,1),padding=\"same\")(MP1)\n",
    "    QConv2  = Lambda(Quantization_layer, arguments = Arguments )(Conv2)\n",
    "    Relu2   = tf.keras.activations.relu(QConv2)\n",
    "    QRelu2  = Lambda(Quantization_layer, arguments = Arguments )(Relu2)\n",
    "    BN2     = BatchNormalization()(QRelu2)\n",
    "    QBN2    = Lambda(Quantization_layer, arguments = Arguments )(BN2)\n",
    "    MP2     = MaxPool2D(pool_size=(3,3), strides=(2,2))(QBN2)\n",
    "    \n",
    "    Conv3   = Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding=\"same\")(MP2)\n",
    "    QConv3  = Lambda(Quantization_layer, arguments = Arguments )(Conv3)\n",
    "    Relu3   = tf.keras.activations.relu(QConv3)\n",
    "    QRelu3  = Lambda(Quantization_layer, arguments = Arguments )(Relu3)\n",
    "    BN3     = BatchNormalization()(QRelu3)\n",
    "    QBN3    = Lambda(Quantization_layer, arguments = Arguments )(BN3)\n",
    "    \n",
    "    Conv4   = Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), padding=\"same\")(QBN3)\n",
    "    QConv4  = Lambda(Quantization_layer, arguments = Arguments )(Conv4)\n",
    "    Relu4   = tf.keras.activations.relu(QConv4)\n",
    "    QRelu4  = Lambda(Quantization_layer, arguments = Arguments )(Relu4)\n",
    "    BN4     = BatchNormalization()(QRelu4)\n",
    "    QBN4    = Lambda(Quantization_layer, arguments = Arguments )(BN4)\n",
    "    \n",
    "    Conv5   = Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), padding=\"same\")(QBN4)\n",
    "    QConv5  = Lambda(Quantization_layer, arguments = Arguments )(Conv5)\n",
    "    Relu5   = tf.keras.activations.relu(QConv5)\n",
    "    QRelu5  = Lambda(Quantization_layer, arguments = Arguments )(Relu5)\n",
    "    BN5     = BatchNormalization()(QRelu5)\n",
    "    QBN5    = Lambda(Quantization_layer, arguments = Arguments )(BN5)\n",
    "    MP5     = MaxPool2D(pool_size=(3,3), strides=(2,2))(QBN5)\n",
    "    \n",
    "    Flat    = Flatten()(MP5)\n",
    "    \n",
    "    Dense6  = Dense(4096)(Flat)\n",
    "    QDense6 = Lambda(Quantization_layer, arguments = Arguments )(Dense6)\n",
    "    Relu6   = tf.keras.activations.relu(QDense6)\n",
    "    QRelu6  = Lambda(Quantization_layer, arguments = Arguments )(Relu6)\n",
    "    Drop6   = Dropout(0.5)(QRelu6)\n",
    "    \n",
    "    Dense7  = Dense(4096)(Drop6)\n",
    "    QDense7 = Lambda(Quantization_layer, arguments = Arguments )(Dense7)\n",
    "    Relu7   = tf.keras.activations.relu(QDense7)\n",
    "    QRelu7  = Lambda(Quantization_layer, arguments = Arguments )(Relu7)\n",
    "    Drop7   = Dropout(0.5)(QRelu7)\n",
    "    \n",
    "    Dense8  = Dense(10)(Drop7)\n",
    "    QDense8 = Lambda(Quantization_layer, arguments = Arguments )(Dense8)\n",
    "    SM8     = tf.keras.activations.softmax(QDense8)\n",
    "    QSM8    = Lambda(Quantization_layer, arguments = Arguments )(SM8)\n",
    "    \n",
    "    return QSM8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Quantized model and Non Quantized model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_layer   = tf.keras.Input((227,227,3))\n",
    "output_layer  = build_model(input_layer, Quantization = False)\n",
    "\n",
    "#For this example we using 8 bits of precision.\n",
    "Qinput_layer  = tf.keras.Input((227,227,3))\n",
    "Qoutput_layer = build_model(Qinput_layer, Quantization = True, word_size = 14, frac_size = 8)\n",
    "\n",
    "AlexNet  = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "QAlexNet = tf.keras.Model(inputs=Qinput_layer, outputs=Qoutput_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Pretrained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Q8qN9xeqzm7"
   },
   "outputs": [],
   "source": [
    "# Loading Wieghts\n",
    "cwd = os.getcwd()\n",
    "Wgt_dir = os.path.join(cwd,'TrainedWeights')\n",
    "Wgt_dir = os.path.join(Wgt_dir,'Weights')\n",
    "AlexNet.load_weights(Wgt_dir)\n",
    "QAlexNet.load_weights(Wgt_dir)\n",
    "\n",
    "# Visualize AlexNet Architecture\n",
    "#AlexNet.summary()\n",
    "\n",
    "# Visualize initialized weights\n",
    "#AlexNet.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantize weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Quantization(List, Quantization = True, signed = True, word_size = 12, frac_size = 6):\n",
    "    factor = 2.0**frac_size\n",
    "    return tf.round(np.array(List)*factor) / factor             #Quantization, assuming no overflow\n",
    "\n",
    "for layer in QAlexNet.layers:\n",
    "    weights = layer.get_weights()\n",
    "    if weights:                     # Layer with weights\n",
    "        # Quantization of Weights and Bias \n",
    "        Qweights    = [Quantization(itm, word_size = 14, frac_size = 8) for itm in weights]\n",
    "        layer.set_weights(Qweights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterator over test Dataset\n",
    "iterator  = iter(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting new image from iterator\n",
    "image     = next(iterator)\n",
    "image_plt = image[0][0,...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Test image\n",
    "plt.imshow(image_plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 3\n",
      "Prediction: 3\n",
      "QPrediction: 3\n"
     ]
    }
   ],
   "source": [
    "# Target\n",
    "tf.print(\"Target:\",np.argmax(image[1]))\n",
    "# Predicted Output\n",
    "print(\"Prediction:\",np.argmax(AlexNet.predict(image[0])))\n",
    "# Quantized Predicted Output\n",
    "print(\"QPrediction:\",np.argmax(QAlexNet.predict(image[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparation of Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.46926502e-05, 1.04233695e-05, 6.94376213e-05, 9.56468999e-01,\n",
       "        6.18058839e-05, 4.23380062e-02, 9.96380695e-04, 2.18989862e-06,\n",
       "        2.01556504e-05, 7.85208795e-06]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AlexNet.predict(image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.9609375 , 0.        ,\n",
       "        0.03515625, 0.        , 0.        , 0.        , 0.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QAlexNet.predict(image[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classes\n",
    "\n",
    "0. airplane\n",
    "1. automobile\n",
    "2. bird\n",
    "3. cat\n",
    "4. deer\n",
    "5. dog\n",
    "6. frog\n",
    "7. horse\n",
    "8. ship\n",
    "9. truck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the general Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization params\n",
    "# -------------------\n",
    "\n",
    "# Loss\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# learning rate\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "# -------------------\n",
    "\n",
    "# Validation metrics\n",
    "# ------------------\n",
    "\n",
    "metrics = ['accuracy']\n",
    "# ------------------\n",
    "\n",
    "# Compile Model\n",
    "AlexNet.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "QAlexNet.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 64s 6ms/step - loss: 0.6316 - accuracy: 0.7898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6315659527876948, 0.7898]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AlexNet.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 63s 6ms/step - loss: 0.6723 - accuracy: 0.7935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6723387817996089, 0.7935]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QAlexNet.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking The Output of Each Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.backend import eager_learning_phase_scope\n",
    "\n",
    "# Function to get outputs from each layer.\n",
    "def get_all_outputs(model, input_data, learning_phase=False):\n",
    "    outputs = [layer.output for layer in model.layers] # exclude Input\n",
    "    layers_fn = K.function([model.input, K.symbolic_learning_phase()], outputs)\n",
    "    return layers_fn([input_data, learning_phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for layer names.\n",
    "\n",
    "Layer_Names = []\n",
    "for layer in AlexNet.layers:\n",
    "    Layer_Names.append(layer.name)\n",
    "\n",
    "QLayer_Names = []\n",
    "for layer in QAlexNet.layers:\n",
    "    QLayer_Names.append(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with layer name -> outputs\n",
    "Layers_Outputs  = dict(zip(Layer_Names, get_all_outputs(AlexNet,image[0])))\n",
    "QLayers_Outputs = dict(zip(QLayer_Names, get_all_outputs(QAlexNet,image[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Outputs for The convolution #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-2.606743  , -1.4824855 , -1.1377517 , ..., -0.8539708 ,\n",
       "           0.3383507 ,  0.21045436],\n",
       "         [-3.0393326 , -2.2158618 , -0.99061877, ..., -1.1680138 ,\n",
       "           0.25034964,  0.28698456],\n",
       "         [-2.8706253 , -2.8723023 , -1.119233  , ..., -1.1876609 ,\n",
       "           0.8022059 ,  0.10838492],\n",
       "         ...,\n",
       "         [-2.458041  , -1.8997049 , -1.3837631 , ..., -0.46334904,\n",
       "           1.4758767 ,  0.21984023],\n",
       "         [-2.0522811 , -1.6578349 , -1.0190948 , ..., -0.5996378 ,\n",
       "           0.8184831 ,  0.0976574 ],\n",
       "         [-1.16906   , -1.1299301 , -0.73243904, ..., -0.5728617 ,\n",
       "           0.01582111, -0.16498914]],\n",
       "\n",
       "        [[-2.2159624 , -1.6978645 , -1.233336  , ..., -0.19716816,\n",
       "           0.2823603 ,  0.31327766],\n",
       "         [-2.9536593 , -2.7829134 , -1.3210441 , ..., -0.5019381 ,\n",
       "           0.2555975 ,  0.4370066 ],\n",
       "         [-2.9007897 , -3.369269  , -1.5034692 , ..., -0.34781575,\n",
       "           1.2196257 ,  0.24811645],\n",
       "         ...,\n",
       "         [-2.450498  , -2.336177  , -1.1198113 , ...,  0.13456355,\n",
       "           2.3169897 ,  0.4583059 ],\n",
       "         [-2.147882  , -1.9764636 , -1.1845266 , ...,  0.21311285,\n",
       "           1.8471265 ,  0.34793192],\n",
       "         [-1.3484695 , -1.3054738 , -1.0554513 , ...,  0.12584534,\n",
       "           0.7170879 , -0.01132448]],\n",
       "\n",
       "        [[-1.1867269 , -1.5790421 , -0.8676639 , ...,  0.19652236,\n",
       "          -0.06649578,  0.48648536],\n",
       "         [-2.0898073 , -2.7585816 , -0.958498  , ..., -0.10219491,\n",
       "          -0.06550816,  0.30064708],\n",
       "         [-2.0106895 , -3.3521178 , -1.3561691 , ...,  0.38735026,\n",
       "           1.6833152 ,  0.0705221 ],\n",
       "         ...,\n",
       "         [-1.690523  , -1.809012  , -0.02633306, ...,  0.05837186,\n",
       "           1.8907229 ,  0.11744975],\n",
       "         [-1.687944  , -1.6546739 , -0.27371588, ...,  0.42522293,\n",
       "           2.5574377 ,  0.28171092],\n",
       "         [-0.9240572 , -0.92833465, -0.4502693 , ...,  0.3768711 ,\n",
       "           1.3697304 ,  0.10223842]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.8951625 ,  2.5932443 , -0.20291898, ..., -0.5296752 ,\n",
       "           0.664403  ,  0.19786286],\n",
       "         [ 2.3480833 ,  3.3586063 , -0.10699441, ..., -1.2042264 ,\n",
       "           0.32263917,  0.6674338 ],\n",
       "         [ 1.9627566 ,  3.810965  , -1.0036768 , ..., -3.1582792 ,\n",
       "           0.2101751 ,  1.0840368 ],\n",
       "         ...,\n",
       "         [ 1.3686876 ,  4.962763  , -1.4703432 , ..., -1.8050331 ,\n",
       "          -0.4297882 ,  0.5950628 ],\n",
       "         [ 1.6440138 ,  3.9411511 , -1.1542951 , ..., -1.4154588 ,\n",
       "          -1.3049266 ,  0.7447358 ],\n",
       "         [ 0.92418575,  2.5879197 , -0.39632368, ..., -0.8517112 ,\n",
       "          -1.0003722 ,  0.8773045 ]],\n",
       "\n",
       "        [[ 0.636385  ,  2.2049787 , -0.15313193, ..., -0.6188544 ,\n",
       "           0.51884323, -0.29659295],\n",
       "         [ 0.9768454 ,  2.714922  , -0.15327716, ..., -0.75833964,\n",
       "           0.37181786, -0.01542203],\n",
       "         [ 1.1825333 ,  3.5978897 , -0.204857  , ..., -1.9981644 ,\n",
       "           0.97616255,  0.45086616],\n",
       "         ...,\n",
       "         [ 1.0550156 ,  3.5302274 , -1.1067698 , ..., -2.0432692 ,\n",
       "          -0.24943838, -0.06926678],\n",
       "         [ 1.5137228 ,  3.1900191 , -1.1269401 , ..., -0.90958345,\n",
       "          -1.2618656 ,  0.09910709],\n",
       "         [ 0.70211655,  2.2922864 , -0.8367338 , ..., -0.36126012,\n",
       "          -1.2543318 ,  0.24669863]],\n",
       "\n",
       "        [[-0.21179013,  1.1438524 , -0.2828037 , ..., -1.0493839 ,\n",
       "           0.34200206, -0.6645177 ],\n",
       "         [-0.06716357,  1.2477355 , -0.09109729, ..., -0.8487526 ,\n",
       "           0.24073297, -0.6959458 ],\n",
       "         [ 0.3636201 ,  1.6383134 ,  0.11183827, ..., -1.5019327 ,\n",
       "           0.67015624, -0.5403406 ],\n",
       "         ...,\n",
       "         [ 0.4118792 ,  1.2782525 , -0.18780524, ..., -2.4654765 ,\n",
       "          -0.25362676, -1.0610535 ],\n",
       "         [ 1.0838643 ,  1.5685636 , -0.25303546, ..., -1.0157859 ,\n",
       "          -0.58816344, -0.59052277],\n",
       "         [ 0.53195727,  1.2652733 , -0.35062176, ..., -0.4257634 ,\n",
       "          -0.6698646 , -0.21992515]]]], dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check AlexNet.summary() to look for specific layer.\n",
    "\n",
    "Layers_Outputs['lambda_180']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-2.6601562 , -1.5195312 , -1.171875  , ..., -0.890625  ,\n",
       "           0.33203125,  0.19921875],\n",
       "         [-3.109375  , -2.28125   , -1.03125   , ..., -1.2265625 ,\n",
       "           0.265625  ,  0.30078125],\n",
       "         [-2.9296875 , -2.9414062 , -1.1679688 , ..., -1.2539062 ,\n",
       "           0.828125  ,  0.1171875 ],\n",
       "         ...,\n",
       "         [-2.5234375 , -1.9609375 , -1.4179688 , ..., -0.53515625,\n",
       "           1.4804688 ,  0.234375  ],\n",
       "         [-2.0898438 , -1.6992188 , -1.0273438 , ..., -0.6484375 ,\n",
       "           0.8203125 ,  0.10546875],\n",
       "         [-1.1757812 , -1.1484375 , -0.73046875, ..., -0.6015625 ,\n",
       "           0.01171875, -0.16015625]],\n",
       "\n",
       "        [[-2.2773438 , -1.7460938 , -1.28125   , ..., -0.2109375 ,\n",
       "           0.28515625,  0.28125   ],\n",
       "         [-3.0390625 , -2.8476562 , -1.3632812 , ..., -0.54296875,\n",
       "           0.2890625 ,  0.4375    ],\n",
       "         [-2.96875   , -3.4492188 , -1.5625    , ..., -0.40234375,\n",
       "           1.265625  ,  0.23828125],\n",
       "         ...,\n",
       "         [-2.5234375 , -2.3710938 , -1.1640625 , ...,  0.0859375 ,\n",
       "           2.3554688 ,  0.47265625],\n",
       "         [-2.1953125 , -2.        , -1.2070312 , ...,  0.1875    ,\n",
       "           1.8671875 ,  0.3515625 ],\n",
       "         [-1.3789062 , -1.3164062 , -1.0664062 , ...,  0.09375   ,\n",
       "           0.71484375, -0.015625  ]],\n",
       "\n",
       "        [[-1.265625  , -1.6328125 , -0.91015625, ...,  0.20703125,\n",
       "          -0.05859375,  0.42578125],\n",
       "         [-2.1835938 , -2.8320312 , -0.9921875 , ..., -0.109375  ,\n",
       "          -0.015625  ,  0.26953125],\n",
       "         [-2.09375   , -3.4375    , -1.4023438 , ...,  0.3671875 ,\n",
       "           1.7851562 ,  0.02734375],\n",
       "         ...,\n",
       "         [-1.7695312 , -1.8671875 , -0.05078125, ...,  0.0625    ,\n",
       "           1.9375    ,  0.10546875],\n",
       "         [-1.7382812 , -1.6796875 , -0.31640625, ...,  0.42578125,\n",
       "           2.6171875 ,  0.27734375],\n",
       "         [-0.9609375 , -0.94921875, -0.48046875, ...,  0.36328125,\n",
       "           1.3945312 ,  0.09765625]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.8320312 ,  2.6289062 , -0.1171875 , ..., -0.55078125,\n",
       "           0.71484375,  0.20703125],\n",
       "         [ 2.2773438 ,  3.4179688 , -0.0546875 , ..., -1.2382812 ,\n",
       "           0.40625   ,  0.67578125],\n",
       "         [ 1.9609375 ,  3.8320312 , -0.91015625, ..., -3.1914062 ,\n",
       "           0.25390625,  1.1015625 ],\n",
       "         ...,\n",
       "         [ 1.359375  ,  4.9609375 , -1.4375    , ..., -1.8632812 ,\n",
       "          -0.41015625,  0.64453125],\n",
       "         [ 1.6445312 ,  3.9023438 , -1.1367188 , ..., -1.4335938 ,\n",
       "          -1.3164062 ,  0.7734375 ],\n",
       "         [ 0.96484375,  2.6132812 , -0.38671875, ..., -0.86328125,\n",
       "          -1.0078125 ,  0.94921875]],\n",
       "\n",
       "        [[ 0.5859375 ,  2.25      , -0.1015625 , ..., -0.59765625,\n",
       "           0.5703125 , -0.27734375],\n",
       "         [ 0.91796875,  2.7695312 , -0.11328125, ..., -0.74609375,\n",
       "           0.44921875, -0.01171875],\n",
       "         [ 1.1992188 ,  3.65625   , -0.171875  , ..., -2.0273438 ,\n",
       "           1.0390625 ,  0.45703125],\n",
       "         ...,\n",
       "         [ 1.0898438 ,  3.5859375 , -1.1328125 , ..., -2.09375   ,\n",
       "          -0.25      , -0.02734375],\n",
       "         [ 1.5507812 ,  3.2109375 , -1.1914062 , ..., -0.93359375,\n",
       "          -1.2890625 ,  0.0859375 ],\n",
       "         [ 0.76171875,  2.3398438 , -0.8828125 , ..., -0.3671875 ,\n",
       "          -1.2890625 ,  0.25390625]],\n",
       "\n",
       "        [[-0.26953125,  1.2109375 , -0.26953125, ..., -1.0078125 ,\n",
       "           0.40625   , -0.6328125 ],\n",
       "         [-0.12890625,  1.3242188 , -0.09765625, ..., -0.8125    ,\n",
       "           0.30859375, -0.6796875 ],\n",
       "         [ 0.36328125,  1.7148438 ,  0.08984375, ..., -1.5039062 ,\n",
       "           0.71875   , -0.53125   ],\n",
       "         ...,\n",
       "         [ 0.40625   ,  1.3242188 , -0.26171875, ..., -2.4882812 ,\n",
       "          -0.23828125, -1.0273438 ],\n",
       "         [ 1.078125  ,  1.625     , -0.35546875, ..., -1.0273438 ,\n",
       "          -0.57421875, -0.59375   ],\n",
       "         [ 0.578125  ,  1.3125    , -0.44921875, ..., -0.4375    ,\n",
       "          -0.7109375 , -0.21875   ]]]], dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check AlexNet.summary() to look for specific layer.\n",
    "\n",
    "QLayers_Outputs['lambda_202']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Max and Min Values of Each Layer for the original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_layers = 50\n",
    "iterator  = iter(test_dataset)\n",
    "image     = next(iterator,'Stop')\n",
    "Max_values = [0]*50\n",
    "Min_values = [0]*50\n",
    "while image != 'Stop':\n",
    "    Model_outputs = get_all_outputs(AlexNet,image[0])\n",
    "    Max_iteration_values = np.array([np.max(itm) for itm in Model_outputs])\n",
    "    Min_iteration_values = np.array([np.min(itm) for itm in Model_outputs])\n",
    "    Max_values = np.maximum(Max_values, Max_iteration_values)\n",
    "    Min_values = np.minimum(Min_values, Min_iteration_values)\n",
    "    image = next(iterator,'Stop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  1.        ,  2.71788788,  2.71788788,  2.71788788,\n",
       "        2.71788788, 16.73804474, 16.73804474, 16.73804474, 20.78150177,\n",
       "       20.78150177, 20.78150177, 20.78150177, 37.55444336, 37.55444336,\n",
       "       37.55444336, 53.57574844, 53.57574844, 53.57574844, 53.57574844,\n",
       "       27.10181808, 27.10181808, 15.17789745, 15.17789745, 15.17789745,\n",
       "       15.17789745, 16.10264778, 16.10264778, 15.52670383, 15.52670383,\n",
       "       15.52670383, 15.52670383, 22.74578285, 22.74578285, 22.74578285,\n",
       "       22.74578285, 46.52299881, 46.52299881, 46.52299881, 46.52299881,\n",
       "       46.52299881, 13.92596149, 13.92596149, 13.92596149, 13.92596149,\n",
       "       13.92596149, 47.77276611, 47.77276611,  1.        ,  1.        ])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Max_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        ,   0.        ,  -2.65676451,  -2.65676451,\n",
       "         0.        ,   0.        ,  -1.95773494,  -1.95773494,\n",
       "        -1.95731556, -29.30832863, -29.30832863,   0.        ,\n",
       "         0.        ,  -1.20609355,  -1.20609355,  -1.20609355,\n",
       "       -61.70952606, -61.70952606,   0.        ,   0.        ,\n",
       "        -1.35015488,  -1.35015488, -17.11544037, -17.11544037,\n",
       "         0.        ,   0.        ,  -0.91049999,  -0.91049999,\n",
       "       -16.34580803, -16.34580803,   0.        ,   0.        ,\n",
       "        -0.84334826,  -0.84334826,  -0.84334826,  -0.84334826,\n",
       "       -79.99137878, -79.99137878,   0.        ,   0.        ,\n",
       "         0.        , -16.63898468, -16.63898468,   0.        ,\n",
       "         0.        ,   0.        , -21.47931671, -21.47931671,\n",
       "         0.        ,   0.        ])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Min_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking max and min values of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.060662657\n",
      "0.054879453\n",
      "1.1514293\n",
      "0.08819208\n",
      "1.2794288\n",
      "0.3740722\n",
      "0.09191583\n",
      "0.035192613\n",
      "1.0881922\n",
      "0.027058428\n",
      "1.9218924\n",
      "3.1125636\n",
      "0.0826775\n",
      "0.033767797\n",
      "1.0528617\n",
      "0.05498081\n",
      "7.267303\n",
      "28.772236\n",
      "0.13753861\n",
      "0.02818342\n",
      "1.0350039\n",
      "0.26688427\n",
      "0.8254347\n",
      "1.505141\n",
      "0.13657723\n",
      "0.006295864\n",
      "0.9885288\n",
      "-0.06251466\n",
      "0.7107444\n",
      "1.0447234\n",
      "0.07450771\n",
      "0.005876748\n",
      "0.07925708\n",
      "0.01865592\n",
      "0.051391937\n",
      "0.024923662\n"
     ]
    }
   ],
   "source": [
    "for itm in AlexNet.get_weights():\n",
    "    print(np.max(itm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.05607786\n",
      "-0.023961341\n",
      "0.7970406\n",
      "-0.07524538\n",
      "1.163794e-36\n",
      "1.1647963e-36\n",
      "-0.10104939\n",
      "-0.036688264\n",
      "0.9350337\n",
      "-0.047507\n",
      "0.056569595\n",
      "0.047031503\n",
      "-0.086561464\n",
      "-0.027074352\n",
      "0.9637472\n",
      "-0.03758461\n",
      "0.18171231\n",
      "0.45579082\n",
      "-0.1344526\n",
      "-0.05151097\n",
      "0.9608286\n",
      "-0.20731844\n",
      "0.3464395\n",
      "0.34071973\n",
      "-0.14339194\n",
      "-0.13129726\n",
      "0.84826046\n",
      "-0.16713257\n",
      "0.19749111\n",
      "0.21392043\n",
      "-0.085306115\n",
      "-0.015681174\n",
      "-0.07879663\n",
      "-0.0409071\n",
      "-0.062905505\n",
      "-0.022243463\n"
     ]
    }
   ],
   "source": [
    "for itm in AlexNet.get_weights():\n",
    "    print(np.min(itm))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "OverfittingAndCallbacks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
