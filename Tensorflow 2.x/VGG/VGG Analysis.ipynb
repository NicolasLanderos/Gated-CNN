{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fZOMjk-2pGPs"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading CIFAR10 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "feuqKVkHqQVW"
   },
   "outputs": [],
   "source": [
    "(_, _), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "# Reducing Target innecessary dimension\n",
    "y_test  = np.squeeze(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dataset Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9YPFldhqV5K"
   },
   "outputs": [],
   "source": [
    "# Normalize Images\n",
    "def normalize_img(x_, y_):\n",
    "    return tf.cast(x_, tf.float32) / 255., y_\n",
    "\n",
    "# 1-hot encoding\n",
    "def to_categorical(x_, y_):\n",
    "    return x_, tf.one_hot(y_, depth=10)\n",
    "\n",
    "# Resizing \n",
    "def process_images(image, label):\n",
    "    # Resize images from 32x32 to 224x224\n",
    "    image = tf.image.resize(image, (224,224))\n",
    "    return image, label\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.map(normalize_img)\n",
    "test_dataset = test_dataset.map(to_categorical)\n",
    "test_dataset = test_dataset.map(process_images)\n",
    "test_dataset = test_dataset.batch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Quantization_layer(tensor, Quantization = True,signed = True, word_size = 12, frac_size = 6):\n",
    "    \n",
    "    factor = 2.0**frac_size\n",
    "    \n",
    "    # Quantized max and min values, in case of the need to implement overflow cases.\n",
    "    #if signed:\n",
    "    #    Max_Qvalue = ((1 << (word_size-1)) - 1)/factor\n",
    "    #    Min_Qvalue = -Max_Qvalue - 1\n",
    "    #else:\n",
    "    #    Max_Qvalue = ((1 << (word_size)) - 1)/factor\n",
    "    #    Min_Qvalue = 0\n",
    "    \n",
    "    if Quantization:\n",
    "        return tf.round(tensor*factor) / factor             #Quantization, assuming no overflow\n",
    "    else:\n",
    "        return tensor                                       #Simple Bypass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvho0zVa0Oti"
   },
   "source": [
    "## Creating VGG Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gL2dc0-iqfc4"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Dense, MaxPool2D, Flatten, Lambda\n",
    "\n",
    "\n",
    "def build_model(input_layer, Quantization = True, signed = True, word_size = 12, frac_size = 6 ):\n",
    "    \n",
    "    Arguments = {'Quantization':Quantization, 'signed':signed, 'word_size':word_size, 'frac_size':frac_size}\n",
    "    QInp      = Lambda(Quantization_layer, arguments = Arguments )(input_layer)\n",
    "    \n",
    "    #Conv Block\n",
    "    Conv1   = Conv2D(filters=64,kernel_size=(3,3),padding=\"same\")(QInp)\n",
    "    QConv1  = Lambda(Quantization_layer, arguments = Arguments )(Conv1)\n",
    "    Relu1   = tf.keras.activations.relu(QConv1)\n",
    "    QRelu1  = Lambda(Quantization_layer, arguments = Arguments )(Relu1)\n",
    "    \n",
    "    Conv2   = Conv2D(filters=64,kernel_size=(3,3),padding=\"same\")(QRelu1)\n",
    "    QConv2  = Lambda(Quantization_layer, arguments = Arguments )(Conv2)\n",
    "    Relu2   = tf.keras.activations.relu(QConv2)\n",
    "    QRelu2  = Lambda(Quantization_layer, arguments = Arguments )(Relu2)\n",
    "    MP2     = MaxPool2D(pool_size=(2,2),strides=(2,2))(QRelu2)\n",
    "    \n",
    "    Conv3   = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\")(MP2)\n",
    "    QConv3  = Lambda(Quantization_layer, arguments = Arguments )(Conv3)\n",
    "    Relu3   = tf.keras.activations.relu(QConv3)\n",
    "    QRelu3  = Lambda(Quantization_layer, arguments = Arguments )(Relu3)\n",
    "    \n",
    "    Conv4   = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\")(QRelu3)\n",
    "    QConv4  = Lambda(Quantization_layer, arguments = Arguments )(Conv4)\n",
    "    Relu4   = tf.keras.activations.relu(QConv4)\n",
    "    QRelu4  = Lambda(Quantization_layer, arguments = Arguments )(Relu4)\n",
    "    MP4     = MaxPool2D(pool_size=(2,2),strides=(2,2))(QRelu4)\n",
    "    \n",
    "    Conv5   = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\")(MP4)\n",
    "    QConv5  = Lambda(Quantization_layer, arguments = Arguments )(Conv5)\n",
    "    Relu5   = tf.keras.activations.relu(QConv5)\n",
    "    QRelu5  = Lambda(Quantization_layer, arguments = Arguments )(Relu5)\n",
    "    \n",
    "    Conv6   = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\")(QRelu5)\n",
    "    QConv6  = Lambda(Quantization_layer, arguments = Arguments )(Conv6)\n",
    "    Relu6   = tf.keras.activations.relu(QConv6)\n",
    "    QRelu6  = Lambda(Quantization_layer, arguments = Arguments )(Relu6)\n",
    "    \n",
    "    Conv7   = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\")(QRelu6)\n",
    "    QConv7  = Lambda(Quantization_layer, arguments = Arguments )(Conv7)\n",
    "    Relu7   = tf.keras.activations.relu(QConv7)\n",
    "    QRelu7  = Lambda(Quantization_layer, arguments = Arguments )(Relu7)\n",
    "    MP7     = MaxPool2D(pool_size=(2,2),strides=(2,2))(QRelu7)\n",
    "    \n",
    "    Conv8   = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\")(MP7)\n",
    "    QConv8  = Lambda(Quantization_layer, arguments = Arguments )(Conv8)\n",
    "    Relu8   = tf.keras.activations.relu(QConv8)\n",
    "    QRelu8  = Lambda(Quantization_layer, arguments = Arguments )(Relu8)\n",
    "    \n",
    "    Conv9   = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\")(QRelu8)\n",
    "    QConv9  = Lambda(Quantization_layer, arguments = Arguments )(Conv9)\n",
    "    Relu9   = tf.keras.activations.relu(QConv9)\n",
    "    QRelu9  = Lambda(Quantization_layer, arguments = Arguments )(Relu9)\n",
    "    \n",
    "    Conv10   = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\")(QRelu9)\n",
    "    QConv10  = Lambda(Quantization_layer, arguments = Arguments )(Conv10)\n",
    "    Relu10   = tf.keras.activations.relu(QConv10)\n",
    "    QRelu10  = Lambda(Quantization_layer, arguments = Arguments )(Relu10)\n",
    "    MP10     = MaxPool2D(pool_size=(2,2),strides=(2,2))(QRelu10)\n",
    "    \n",
    "    Conv11   = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\")(MP10)\n",
    "    QConv11  = Lambda(Quantization_layer, arguments = Arguments )(Conv11)\n",
    "    Relu11   = tf.keras.activations.relu(QConv11)\n",
    "    QRelu11  = Lambda(Quantization_layer, arguments = Arguments )(Relu11)\n",
    "    \n",
    "    Conv12   = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\")(QRelu11)\n",
    "    QConv12  = Lambda(Quantization_layer, arguments = Arguments )(Conv12)\n",
    "    Relu12   = tf.keras.activations.relu(QConv12)\n",
    "    QRelu12  = Lambda(Quantization_layer, arguments = Arguments )(Relu12)\n",
    "    \n",
    "    Conv13   = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\")(QRelu12)\n",
    "    QConv13  = Lambda(Quantization_layer, arguments = Arguments )(Conv13)\n",
    "    Relu13   = tf.keras.activations.relu(QConv13)\n",
    "    QRelu13  = Lambda(Quantization_layer, arguments = Arguments )(Relu13)\n",
    "    MP13     = MaxPool2D(pool_size=(2,2),strides=(2,2))(QRelu13)\n",
    "    \n",
    "    Flat    = Flatten()(MP13)\n",
    "    \n",
    "    Dense14  = Dense(4096)(Flat)\n",
    "    QDense14 = Lambda(Quantization_layer, arguments = Arguments )(Dense14)\n",
    "    Relu14   = tf.keras.activations.relu(QDense14)\n",
    "    QRelu14  = Lambda(Quantization_layer, arguments = Arguments )(Relu14)\n",
    "    \n",
    "    Dense15  = Dense(4096)(QRelu14)\n",
    "    QDense15 = Lambda(Quantization_layer, arguments = Arguments )(Dense15)\n",
    "    Relu15   = tf.keras.activations.relu(QDense15)\n",
    "    QRelu15  = Lambda(Quantization_layer, arguments = Arguments )(Relu15)\n",
    "    \n",
    "    Dense16  = Dense(10)(QRelu15)\n",
    "    QDense16 = Lambda(Quantization_layer, arguments = Arguments )(Dense16)\n",
    "    SM16     = tf.keras.activations.softmax(QDense16)\n",
    "    QSM16    = Lambda(Quantization_layer, arguments = Arguments )(SM16)\n",
    "    \n",
    "    return QSM16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Quantized model and Non Quantized model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer   = tf.keras.Input((224,224,3))\n",
    "output_layer  = build_model(input_layer, Quantization = False)\n",
    "\n",
    "#For this example we using 8 bits of precision.\n",
    "Qinput_layer  = tf.keras.Input((224,224,3))\n",
    "Qoutput_layer = build_model(Qinput_layer, Quantization = True, word_size = 14, frac_size = 8)\n",
    "\n",
    "VGG16  = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "QVGG16 = tf.keras.Model(inputs=Qinput_layer, outputs=Qoutput_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Pretrained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Q8qN9xeqzm7"
   },
   "outputs": [],
   "source": [
    "# Loading Wieghts\n",
    "cwd = os.getcwd()\n",
    "Wgt_dir = os.path.join(cwd,'TrainedWeights')\n",
    "Wgt_dir = os.path.join(Wgt_dir,'Weights')\n",
    "VGG16.load_weights(Wgt_dir)\n",
    "QVGG16.load_weights(Wgt_dir)\n",
    "\n",
    "# Visualize AlexNet Architecture\n",
    "#VGG16.summary()\n",
    "\n",
    "# Visualize initialized weights\n",
    "#VGG16.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantize weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Quantization(List, Quantization = True, signed = True, word_size = 12, frac_size = 6):\n",
    "    factor = 2.0**frac_size\n",
    "    return tf.round(np.array(List)*factor) / factor             #Quantization, assuming no overflow\n",
    "\n",
    "for layer in QVGG16.layers:\n",
    "    weights = layer.get_weights()\n",
    "    if weights:                     # Layer with weights\n",
    "        # Quantization of Weights and Bias \n",
    "        Qweights    = [Quantization(itm, word_size = 14, frac_size = 8) for itm in weights]\n",
    "        layer.set_weights(Qweights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterator over test Dataset\n",
    "iterator  = iter(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting new image from iterator\n",
    "image     = next(iterator)\n",
    "image_plt = image[0][0,...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Test image\n",
    "plt.imshow(image_plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 3\n",
      "Prediction: 3\n",
      "QPrediction: 3\n"
     ]
    }
   ],
   "source": [
    "# Target\n",
    "tf.print(\"Target:\",np.argmax(image[1]))\n",
    "# Predicted Output\n",
    "print(\"Prediction:\",np.argmax(VGG16.predict(image[0])))\n",
    "# Quantized Predicted Output\n",
    "print(\"QPrediction:\",np.argmax(QVGG16.predict(image[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparation of Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.9180329e-04, 2.3970929e-04, 3.2078254e-03, 6.8547988e-01,\n",
       "        2.5826562e-03, 2.8004652e-01, 1.9593343e-02, 5.7677077e-03,\n",
       "        2.2453316e-03, 6.4517255e-04]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VGG16.predict(image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.00390625, 0.68359375, 0.00390625,\n",
       "        0.2890625 , 0.015625  , 0.00390625, 0.        , 0.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QVGG16.predict(image[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classes\n",
    "\n",
    "0. airplane\n",
    "1. automobile\n",
    "2. bird\n",
    "3. cat\n",
    "4. deer\n",
    "5. dog\n",
    "6. frog\n",
    "7. horse\n",
    "8. ship\n",
    "9. truck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the general Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization params\n",
    "# -------------------\n",
    "\n",
    "# Loss\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# learning rate\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "# -------------------\n",
    "\n",
    "# Validation metrics\n",
    "# ------------------\n",
    "\n",
    "metrics = ['accuracy']\n",
    "# ------------------\n",
    "\n",
    "# Compile Model\n",
    "VGG16.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "QVGG16.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 141s 14ms/step - loss: 0.8012 - accuracy: 0.7349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8012385272836876, 0.7349]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VGG16.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 172s 17ms/step - loss: 0.8922 - accuracy: 0.7359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8922459922850597, 0.7359]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QVGG16.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking The Output of Each Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.backend import eager_learning_phase_scope\n",
    "\n",
    "# Function to get outputs from each layer.\n",
    "def get_all_outputs(model, input_data, learning_phase=False):\n",
    "    outputs = [layer.output for layer in model.layers] # exclude Input\n",
    "    layers_fn = K.function([model.input, K.symbolic_learning_phase()], outputs)\n",
    "    return layers_fn([input_data, learning_phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for layer names.\n",
    "\n",
    "Layer_Names = []\n",
    "for layer in VGG16.layers:\n",
    "    Layer_Names.append(layer.name)\n",
    "\n",
    "QLayer_Names = []\n",
    "for layer in QVGG16.layers:\n",
    "    QLayer_Names.append(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with layer name -> outputs\n",
    "Layers_Outputs  = dict(zip(Layer_Names, get_all_outputs(VGG16,image[0])))\n",
    "QLayers_Outputs = dict(zip(QLayer_Names, get_all_outputs(QVGG16,image[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Outputs for The convolution #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Layers_Outputs['lambda_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QLayers_Outputs['lambda_38']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Max and Min Values of Each Layer for the original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_layers  = 72\n",
    "iterator  = iter(test_dataset)\n",
    "image     = next(iterator,'Stop')\n",
    "Max_values = [0]*72\n",
    "Min_values = [0]*72\n",
    "while image != 'Stop':\n",
    "    Model_outputs = get_all_outputs(VGG16,image[0])\n",
    "    Max_iteration_values = np.array([np.max(itm) for itm in Model_outputs])\n",
    "    Min_iteration_values = np.array([np.min(itm) for itm in Model_outputs])\n",
    "    Max_values = np.maximum(Max_values, Max_iteration_values)\n",
    "    Min_values = np.minimum(Min_values, Min_iteration_values)\n",
    "    image = next(iterator,'Stop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  1.        ,  0.55289382,  0.55289382,  0.55289382,\n",
       "        0.55289382,  0.56202006,  0.56202006,  0.56202006,  0.56202006,\n",
       "        0.56202006,  0.40619522,  0.40619522,  0.40619522,  0.40619522,\n",
       "        0.57603204,  0.57603204,  0.57603204,  0.57603204,  0.57603204,\n",
       "        0.672952  ,  0.672952  ,  0.672952  ,  0.672952  ,  1.06780303,\n",
       "        1.06780303,  1.06780303,  1.06780303,  1.74278188,  1.74278188,\n",
       "        1.74278188,  1.74278188,  1.74278188,  1.6580162 ,  1.6580162 ,\n",
       "        1.6580162 ,  1.6580162 ,  1.94520521,  1.94520521,  1.94520521,\n",
       "        1.94520521,  2.26748776,  2.26748776,  2.26748776,  2.26748776,\n",
       "        2.26748776,  2.46216726,  2.46216726,  2.46216726,  2.46216726,\n",
       "        3.3225956 ,  3.3225956 ,  3.3225956 ,  3.3225956 ,  3.02389812,\n",
       "        3.02389812,  3.02389812,  3.02389812,  3.02389812,  3.02389812,\n",
       "        4.39980793,  4.39980793,  4.39980793,  4.39980793,  4.64638805,\n",
       "        4.64638805,  4.64638805,  4.64638805, 44.03063965, 44.03063965,\n",
       "        1.        ,  1.        ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Max_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        ,   0.        ,  -0.67023152,  -0.67023152,\n",
       "         0.        ,   0.        ,  -0.55003768,  -0.55003768,\n",
       "         0.        ,   0.        ,   0.        ,  -0.65099853,\n",
       "        -0.65099853,   0.        ,   0.        ,  -0.53201503,\n",
       "        -0.53201503,   0.        ,   0.        ,   0.        ,\n",
       "        -0.66176283,  -0.66176283,   0.        ,   0.        ,\n",
       "        -0.94754082,  -0.94754082,   0.        ,   0.        ,\n",
       "        -1.39863992,  -1.39863992,   0.        ,   0.        ,\n",
       "         0.        ,  -1.55851161,  -1.55851161,   0.        ,\n",
       "         0.        ,  -2.03468847,  -2.03468847,   0.        ,\n",
       "         0.        ,  -3.00645447,  -3.00645447,   0.        ,\n",
       "         0.        ,   0.        ,  -3.01076388,  -3.01076388,\n",
       "         0.        ,   0.        ,  -3.67845058,  -3.67845058,\n",
       "         0.        ,   0.        ,  -5.63244438,  -5.63244438,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "        -5.26455212,  -5.26455212,   0.        ,   0.        ,\n",
       "        -3.85044432,  -3.85044432,   0.        ,   0.        ,\n",
       "       -27.04880524, -27.04880524,   0.        ,   0.        ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Min_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking max and min values of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.105967745\n",
      "0.014988257\n",
      "0.09595051\n",
      "0.011936342\n",
      "0.10281713\n",
      "0.015564269\n",
      "0.08596791\n",
      "0.019136881\n",
      "0.09624452\n",
      "0.012335057\n",
      "0.07714346\n",
      "0.012018733\n",
      "0.067087404\n",
      "0.011228289\n",
      "0.07069143\n",
      "0.016360529\n",
      "0.08120797\n",
      "0.021275712\n",
      "0.07580003\n",
      "0.018184675\n",
      "0.0711499\n",
      "0.036662944\n",
      "0.07354726\n",
      "0.033380628\n",
      "0.06902299\n",
      "0.032600958\n",
      "0.064379156\n",
      "0.026954189\n",
      "0.071879946\n",
      "0.03205061\n",
      "0.053636953\n",
      "0.011063661\n"
     ]
    }
   ],
   "source": [
    "for itm in VGG16.get_weights():\n",
    "    print(np.max(itm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.115536876\n",
      "-0.016275147\n",
      "-0.10245023\n",
      "-0.016122118\n",
      "-0.08389944\n",
      "-0.017848462\n",
      "-0.087104104\n",
      "-0.017060434\n",
      "-0.08118384\n",
      "-0.014572672\n",
      "-0.0745357\n",
      "-0.011928877\n",
      "-0.074435614\n",
      "-0.012825207\n",
      "-0.07202102\n",
      "-0.014688623\n",
      "-0.06944868\n",
      "-0.013372264\n",
      "-0.083173715\n",
      "-0.03949675\n",
      "-0.07473356\n",
      "-0.02615708\n",
      "-0.07346563\n",
      "-0.036137845\n",
      "-0.07589335\n",
      "-0.040974997\n",
      "-0.07180178\n",
      "-0.015379306\n",
      "-0.06817566\n",
      "-0.014832148\n",
      "-0.07294732\n",
      "-0.011839713\n"
     ]
    }
   ],
   "source": [
    "for itm in VGG16.get_weights():\n",
    "    print(np.min(itm))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "OverfittingAndCallbacks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
