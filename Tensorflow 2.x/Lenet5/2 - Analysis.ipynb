{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fZOMjk-2pGPs"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path para importacion de funciones\n",
    "dir_current    = os.path.abspath('')\n",
    "dir_parent = os.path.dirname(dir_current)\n",
    "if not dir_parent in sys.path: sys.path.append(dir_parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "feuqKVkHqQVW"
   },
   "outputs": [],
   "source": [
    "(_, _), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "# Normalizando\n",
    "x_test = x_test/255.\n",
    "# Expandiendo dimensiones desde (28x28) a (28x28x1)\n",
    "x_test = tf.expand_dims(x_test, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dataset Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Z9YPFldhqV5K"
   },
   "outputs": [],
   "source": [
    "from functions import to_categorical\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.map(to_categorical)\n",
    "test_dataset = test_dataset.batch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Quantized model and Non Quantized model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Lenet_body\n",
    "\n",
    "input_layer   = tf.keras.Input((28, 28, 1))\n",
    "output_layer  = Lenet_body(input_layer, Quantization = False)\n",
    "\n",
    "#For this example we using 3 bits of precision.\n",
    "Qinput_layer  = tf.keras.Input((28, 28, 1))\n",
    "Qoutput_layer = Lenet_body(Qinput_layer, Quantization = True, word_size = 12, frac_size = 3)\n",
    "\n",
    "Lenet  = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "QLenet = tf.keras.Model(inputs=Qinput_layer, outputs=Qoutput_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Pretrained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-Q8qN9xeqzm7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x26680659c08>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "Wgt_dir = os.path.join(cwd,'TrainedWeights')\n",
    "Wgt_dir = os.path.join(Wgt_dir,'Weights')\n",
    "\n",
    "Lenet.load_weights(Wgt_dir)\n",
    "QLenet.load_weights(Wgt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantize Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Weight_Quantization\n",
    "Weight_Quantization(model = QLenet, Frac_Bits = 8, Int_Bits = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Iterator over test Dataset\n",
    "iterator  = iter(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 9\n",
      "Prediction: 9\n",
      "QPrediction: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Getting new image from iterator\n",
    "image     = next(iterator)\n",
    "image_plt = image[0][0,...,0]\n",
    "\n",
    "# Plotting Test image\n",
    "plt.imshow(image_plt, cmap='gray')\n",
    "\n",
    "# Target\n",
    "tf.print(\"Target:\",np.argmax(image[1]))\n",
    "# Predicted Output\n",
    "print(\"Prediction:\",np.argmax(Lenet.predict(image[0])))\n",
    "# Quantized Predicted Output\n",
    "print(\"QPrediction:\",np.argmax(QLenet.predict(image[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparation of Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.4945015e-08, 7.8437586e-07, 4.5743948e-07, 2.4961669e-06,\n",
       "        1.6386039e-06, 1.5448232e-03, 8.7722611e-07, 5.2541746e-03,\n",
       "        1.1379937e-05, 9.9318331e-01]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lenet.predict(image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QLenet.predict(image[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classes\n",
    "\n",
    "0. T-shirt/top\n",
    "1. Trouser\n",
    "2. Pullover\n",
    "3. Dress\n",
    "4. Coat\n",
    "5. Sandal\n",
    "6. Shirt\n",
    "7. Sneaker\n",
    "8. Bag\n",
    "9. Ankle boot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the general Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization params\n",
    "# -------------------\n",
    "\n",
    "# Loss\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# learning rate\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "# -------------------\n",
    "\n",
    "# Validation metrics\n",
    "# ------------------\n",
    "\n",
    "metrics = ['accuracy']\n",
    "# ------------------\n",
    "\n",
    "# Compile Model\n",
    "Lenet.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "QLenet.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 33s 3ms/step - loss: 0.3196 - accuracy: 0.8883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.31960160391857567, 0.8883]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lenet.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 31s 3ms/step - loss: 0.6453 - accuracy: 0.8847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.645292562094331, 0.8847]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QLenet.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how even with low precicion of the fractional (3 bits) the network accuracy is almost unaffected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking The Output of Each Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import get_all_outputs\n",
    "# List for layer names.\n",
    "\n",
    "Layer_Names = []\n",
    "for layer in Lenet.layers:\n",
    "    Layer_Names.append(layer.name)\n",
    "\n",
    "QLayer_Names = []\n",
    "for layer in QLenet.layers:\n",
    "    QLayer_Names.append(layer.name)\n",
    "    \n",
    "# Dictionary with layer name -> outputs\n",
    "Layers_Outputs  = dict(zip(Layer_Names, get_all_outputs(Lenet,image[0])))\n",
    "QLayers_Outputs = dict(zip(QLayer_Names, get_all_outputs(QLenet,image[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Max and Min Values of Each Layer for the original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_layers  = len(QLenet.layers)\n",
    "iterator  = iter(test_dataset)\n",
    "image     = next(iterator,'Stop')\n",
    "Max_values = [0]*N_layers\n",
    "Min_values = [0]*N_layers\n",
    "while image != 'Stop':\n",
    "    Model_outputs = get_all_outputs(Lenet,image[0])\n",
    "    Max_iteration_values = np.array([np.max(itm) for itm in Model_outputs])\n",
    "    Min_iteration_values = np.array([np.min(itm) for itm in Model_outputs])\n",
    "    Max_values = np.maximum(Max_values, Max_iteration_values)\n",
    "    Min_values = np.minimum(Min_values, Min_iteration_values)\n",
    "    image = next(iterator,'Stop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  1.        ,  6.51962948,  6.51962948,  0.99999565,\n",
       "        0.99999565,  0.99997681, 11.36214638, 11.36214638,  1.        ,\n",
       "        1.        ,  0.99999976,  0.99999976, 15.4092989 , 15.4092989 ,\n",
       "        1.        ,  1.        , 10.59511375, 10.59511375,  1.        ,\n",
       "        1.        , 15.80233192, 15.80233192,  0.99999881,  0.99999881])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Max_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        ,   0.        ,  -3.21593666,  -3.21593666,\n",
       "        -0.9967863 ,  -0.9967863 ,  -0.99342388, -12.16223907,\n",
       "       -12.16223907,  -1.        ,  -1.        ,  -0.99999869,\n",
       "        -0.99999869, -15.66343212, -15.66343212,  -1.        ,\n",
       "        -1.        , -11.51284122, -11.51284122,  -1.        ,\n",
       "        -1.        , -11.09358406, -11.09358406,   0.        ,\n",
       "         0.        ])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Min_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Max and Min values of Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6256596\n",
      "0.21230586\n",
      "0.9251389\n",
      "0.18390743\n",
      "0.62760293\n",
      "0.24772961\n",
      "0.54453754\n",
      "0.20400645\n",
      "0.72902125\n",
      "0.05587189\n"
     ]
    }
   ],
   "source": [
    "for itm in Lenet.get_weights():\n",
    "    print(np.max(itm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.58532584\n",
      "-0.2912165\n",
      "-0.80219436\n",
      "-0.19225334\n",
      "-0.9469629\n",
      "-0.23552617\n",
      "-0.6235763\n",
      "-0.22716506\n",
      "-0.6461236\n",
      "-0.07768464\n"
     ]
    }
   ],
   "source": [
    "for itm in Lenet.get_weights():\n",
    "    print(np.min(itm))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "OverfittingAndCallbacks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
