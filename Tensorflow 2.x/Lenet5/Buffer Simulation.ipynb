{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from fxpmath import Fxp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargando el modelo (mismo codigo que usado durante el desarrollado en tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Quantization_layer(tensor, Quantization = True,signed = True, word_size = 12, frac_size = 6):\n",
    "    \n",
    "    factor = 2.0**frac_size\n",
    "    \n",
    "    if Quantization:\n",
    "        return tf.round(tensor*factor) / factor             #Quantization, assuming no overflow\n",
    "    else:\n",
    "        return tensor                                       #Simple Bypass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_layer, Quantization = True, signed = True, word_size = 12, frac_size = 6 ):\n",
    "    Arguments = {'Quantization':Quantization, 'signed':signed, 'word_size':word_size, 'frac_size':frac_size}\n",
    "    QInp      = tf.keras.layers.Lambda(Quantization_layer, name=\"QInp\",  arguments = Arguments )(input_layer)\n",
    "    #Conv Block\n",
    "    Conv1   = tf.keras.layers.Conv2D(6, kernel_size=5, strides=1, input_shape=(28,28,1), padding='same', name= 'Conv1')(QInp)\n",
    "    QConv1  = tf.keras.layers.Lambda(Quantization_layer, name=\"QConv1\",  arguments = Arguments )(Conv1)\n",
    "    Act1    = tf.keras.activations.tanh(QConv1)\n",
    "    QAct1   = tf.keras.layers.Lambda(Quantization_layer, name=\"QAct1\",   arguments = Arguments )(Act1)\n",
    "    AvgPool1= tf.keras.layers.AveragePooling2D(name='AvgPool1')(QAct1)\n",
    "    #Conv Block\n",
    "    Conv2   = tf.keras.layers.Conv2D(16, kernel_size=5, strides=1, padding='valid',name='Conv2')(AvgPool1)\n",
    "    QConv2  = tf.keras.layers.Lambda(Quantization_layer, name=\"QConv2\",  arguments = Arguments )(Conv2)\n",
    "    Act2    = tf.keras.activations.tanh(QConv2)\n",
    "    QAct2   = tf.keras.layers.Lambda(Quantization_layer, name=\"QAct2\",   arguments = Arguments )(Act2)\n",
    "    AvgPool2= tf.keras.layers.AveragePooling2D(name='AvgPool2')(QAct2)\n",
    "    Flatten = tf.keras.layers.Flatten(name='Flatten')(AvgPool2)\n",
    "    #Dense Block\n",
    "    Dense1  = tf.keras.layers.Dense(units=120, name='Dense1')(Flatten)\n",
    "    QDense1 = tf.keras.layers.Lambda(Quantization_layer, name=\"QDense1\", arguments = Arguments )(Dense1)\n",
    "    Act3    = tf.keras.activations.tanh(QDense1)\n",
    "    QAct3   = tf.keras.layers.Lambda(Quantization_layer, name=\"QAct3\",   arguments = Arguments )(Act3)\n",
    "    #Dense Block\n",
    "    Dense2  = tf.keras.layers.Dense(units=84, name='Dense2')(QAct3)\n",
    "    QDense2 = tf.keras.layers.Lambda(Quantization_layer, name=\"QDense2\", arguments = Arguments)(Dense2)\n",
    "    Act4    = tf.keras.activations.tanh(QDense2)\n",
    "    QAct4   = tf.keras.layers.Lambda(Quantization_layer, name=\"QAct4\",   arguments = Arguments)(Act4)\n",
    "    #Output Block\n",
    "    Out     = tf.keras.layers.Dense(units=10,name='Output')(QAct4)\n",
    "    QOut    = tf.keras.layers.Lambda(Quantization_layer, name=\"QOut\",    arguments = Arguments)(Out)\n",
    "    Act5    = tf.keras.activations.softmax(QOut)\n",
    "    QAct5   = tf.keras.layers.Lambda(Quantization_layer, name=\"QSoftmax\",arguments = Arguments)(Act5)\n",
    "    \n",
    "    return QAct5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Qinput_layer  = tf.keras.Input((28, 28, 1))\n",
    "Qoutput_layer = build_model(Qinput_layer, Quantization = True, word_size = 16, frac_size = 8)\n",
    "\n",
    "QLenet = tf.keras.Model(inputs=Qinput_layer, outputs=Qoutput_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x285c8a2cc08>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "Wgt_dir = os.path.join(cwd,'TrainedWeights')\n",
    "Wgt_dir = os.path.join(Wgt_dir,'Weights')\n",
    "QLenet.load_weights(Wgt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Quantization(List, Quantization = True, signed = True, word_size = 12, frac_size = 6):\n",
    "    factor = 2.0**frac_size\n",
    "    return tf.round(np.array(List)*factor) / factor             #Quantization, assuming no overflow\n",
    "\n",
    "for layer in QLenet.layers:\n",
    "    weights = layer.get_weights()\n",
    "    if weights:                     # Layer with weights\n",
    "        # Quantization of Weights and Bias \n",
    "        Qweights    = [None,None]\n",
    "        Qweights[0] = Quantization(weights[0], word_size = 12, frac_size = 3)\n",
    "        Qweights[1] = Quantization(weights[1], word_size = 12, frac_size = 3)\n",
    "        layer.set_weights(Qweights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos de Simulacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Referente a la cuantizacion\n",
    "Sign_bits = 1\n",
    "Int_bits  = 7\n",
    "Frac_bits = 8\n",
    "Word_bits = Sign_bits + Int_bits + Frac_bits\n",
    "\n",
    "# Referente a los buffers\n",
    "IOBuffer_size = 4704*Word_bits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IOBuffer_1 = np.zeros(IOBuffer_size,dtype=int)\n",
    "IOBuffer_2 = np.zeros(IOBuffer_size,dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargando los datos en el buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "(_, _), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "x_test = x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Quantization(array, Quantization = True):\n",
    "    \n",
    "    factor = 2.0**Frac_bits\n",
    "    \n",
    "    if Quantization:\n",
    "        return np.round(array*factor) / factor             #Quantization, assuming no overflow\n",
    "    else:\n",
    "        return array                                       #Simple Bypass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_x_test = Quantization(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la imagen es guardada pixel a pixel de izquierda a derecha, de arriba a abajo.\n",
    "def Load_Image_grayscale(buffer, data):\n",
    "    index = 0\n",
    "    for row in data:\n",
    "        for pixel in row:\n",
    "            binary_pixel = Fxp(pixel,True,Word_bits,Frac_bits)\n",
    "            binary_pixel = binary_pixel.bin()\n",
    "            for bit in binary_pixel:\n",
    "                buffer[index] = bit\n",
    "                index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Load_Image_grayscale(IOBuffer_1,sim_x_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcion para obtener activaciones de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = tf.expand_dims(x_test,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.backend import eager_learning_phase_scope\n",
    "\n",
    "# Function to get outputs from each layer.\n",
    "def get_all_outputs(model, input_data, learning_phase=False):\n",
    "    outputs = [layer.output for layer in model.layers] # exclude Input\n",
    "    layers_fn = K.function([model.input, K.symbolic_learning_phase()], outputs)\n",
    "    return layers_fn([input_data, learning_phase])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcion para escribir en buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_conv_output(data,offset,buffer):\n",
    "    binary_data = Fxp(data,True,Word_bits,Frac_bits)\n",
    "    binary_data = binary_data.bin()\n",
    "    index = offset\n",
    "    for bit in binary_data:\n",
    "        buffer[index] = bit\n",
    "        index = index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estadisticas de buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_IOBuffer_1 = np.zeros((4,IOBuffer_size),dtype=int)\n",
    "stats_IOBuffer_2 = np.zeros((4,IOBuffer_size),dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buffer_stadistics(data_buffer,stats_buffer,n_cycles):\n",
    "    # (last value, # cambios logicos, # ciclos almacenando 0, # ciclos almacenando 1)\n",
    "    index = 0\n",
    "    while index < len(data_buffer):\n",
    "        if data_buffer[index] != stats_buffer[0,index]:\n",
    "            stats_buffer[1,index] = stats_buffer[1,index]  + 1\n",
    "        if data_buffer[index] == 0:\n",
    "            stats_buffer[2,index] = stats_buffer[2,index]  + n_cycles\n",
    "        if data_buffer[index] == 1:\n",
    "            stats_buffer[3,index] = stats_buffer[3,index]  + n_cycles\n",
    "        stats_buffer[0,index] = data_buffer[index]\n",
    "        index = index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inicia simulacion\n",
      "Capa Convolucional\n",
      "Ciclos procesados: 784\n",
      "Capa AvgPool\n",
      "Ciclos procesados: 833\n",
      "Capa Convolucional\n",
      "Ciclos procesados: 1100\n",
      "Capa AvgPool\n",
      "Ciclos procesados: 1117\n",
      "Capa FC\n",
      "Ciclos procesados: 1477\n",
      "Capa FC\n",
      "Ciclos procesados: 1519\n",
      "Capa FC\n",
      "Ciclos procesados: 1523\n"
     ]
    }
   ],
   "source": [
    "print(\"inicia simulacion\")\n",
    "cycles = 0                  # Contador de ciclos\n",
    "print(\"Capa Convolucional\")\n",
    "# Offsets para escritura en memoria\n",
    "map_offset    = 28*28*16\n",
    "row_offset    = 28*16\n",
    "column_offset = 16\n",
    "# Indices de lectura.\n",
    "row     = 0\n",
    "column  = 0\n",
    "act_map = 0\n",
    "outputs = get_all_outputs(QLenet, tf.expand_dims(x_test[0],axis=0))\n",
    "layer_outputs = outputs[5]  # activaciones de la capa convolucional\n",
    "outs_per_cycle = 6          # Numero de activaciones que se calculan por ciclo.\n",
    "# Primer ciclo recorre la capa convolucional, el segundo las convoluciones de cada ciclo.\n",
    "while True:\n",
    "    cycles = cycles + 1\n",
    "    counter = 0\n",
    "    while True:\n",
    "        out = layer_outputs[0,row,column,act_map]\n",
    "        write_conv_output(out,act_map*map_offset + row*row_offset + column*column_offset, IOBuffer_2)\n",
    "        if act_map == 5:\n",
    "            act_map = -1\n",
    "            column  = column + 1\n",
    "        if column == 28:\n",
    "            column  = 0\n",
    "            row     = row + 1\n",
    "        if row == 28:\n",
    "            break\n",
    "        act_map = act_map + 1\n",
    "        counter = counter + 1\n",
    "        if counter == outs_per_cycle:\n",
    "            break\n",
    "    # Luego de cada ciclo se revisa el buffer para actualizar las estadisticas.\n",
    "    buffer_stadistics(IOBuffer_2,stats_IOBuffer_2,1)\n",
    "    if row == 28:\n",
    "        break\n",
    "print(\"Ciclos procesados:\",cycles)\n",
    "print(\"Capa AvgPool\")\n",
    "# Analogo a la capa anterior\n",
    "map_offset    = 14*14*16\n",
    "row_offset    = 14*16\n",
    "column_offset = 16\n",
    "row     = 0\n",
    "column  = 0\n",
    "act_map = 0\n",
    "layer_outputs = outputs[6]\n",
    "outs_per_cycle = 24\n",
    "while True:\n",
    "    cycles = cycles + 1\n",
    "    counter = 0\n",
    "    while True:\n",
    "        out = layer_outputs[0,row,column,act_map]\n",
    "        write_conv_output(out,act_map*map_offset + row*row_offset + column*column_offset, IOBuffer_1)\n",
    "        if act_map == 5:\n",
    "            act_map = -1\n",
    "            column  = column + 1\n",
    "        if column == 14:\n",
    "            column  = 0\n",
    "            row     = row + 1\n",
    "        if row == 14:\n",
    "            break\n",
    "        act_map = act_map + 1\n",
    "        counter = counter + 1\n",
    "        if counter == outs_per_cycle:\n",
    "            break\n",
    "    buffer_stadistics(IOBuffer_1,stats_IOBuffer_1,1)\n",
    "    if row == 14:\n",
    "        break\n",
    "print(\"Ciclos procesados:\",cycles)\n",
    "print(\"Capa Convolucional\")\n",
    "map_offset    = 10*10*16\n",
    "row_offset    = 10*16\n",
    "column_offset = 16\n",
    "row     = 0\n",
    "column  = 0\n",
    "act_map = 0\n",
    "layer_outputs = outputs[10]\n",
    "outs_per_cycle = 6\n",
    "while True:\n",
    "    cycles = cycles + 1\n",
    "    counter = 0\n",
    "    while True:\n",
    "        out = layer_outputs[0,row,column,act_map]\n",
    "        write_conv_output(out,act_map*map_offset + row*row_offset + column*column_offset, IOBuffer_2)\n",
    "        if act_map == 15:\n",
    "            act_map = -1\n",
    "            column  = column + 1\n",
    "        if column == 10:\n",
    "            column  = 0\n",
    "            row     = row + 1\n",
    "        if row == 10:\n",
    "            break\n",
    "        act_map = act_map + 1\n",
    "        counter = counter + 1\n",
    "        if counter == outs_per_cycle:\n",
    "            break\n",
    "    buffer_stadistics(IOBuffer_2,stats_IOBuffer_2,1)\n",
    "    if row == 10:\n",
    "        break\n",
    "print(\"Ciclos procesados:\",cycles)\n",
    "print(\"Capa AvgPool\")\n",
    "map_offset    = 5*5*16\n",
    "row_offset    = 5*16\n",
    "column_offset = 16\n",
    "row     = 0\n",
    "column  = 0\n",
    "act_map = 0\n",
    "layer_outputs = outputs[11]\n",
    "outs_per_cycle = 24\n",
    "while True:\n",
    "    cycles = cycles + 1\n",
    "    counter = 0\n",
    "    while True:\n",
    "        out = layer_outputs[0,row,column,act_map]\n",
    "        write_conv_output(out,act_map*map_offset + row*row_offset + column*column_offset, IOBuffer_1)\n",
    "        if act_map == 15:\n",
    "            act_map = -1\n",
    "            column  = column + 1\n",
    "        if column == 5:\n",
    "            column  = 0\n",
    "            row     = row + 1\n",
    "        if row == 5:\n",
    "            break\n",
    "        act_map = act_map + 1\n",
    "        counter = counter + 1\n",
    "        if counter == outs_per_cycle:\n",
    "            break\n",
    "    buffer_stadistics(IOBuffer_1,stats_IOBuffer_1,1)\n",
    "    if row == 5:\n",
    "        break\n",
    "print(\"Ciclos procesados:\",cycles)\n",
    "print(\"Capa FC\")\n",
    "# en este caso dado que son muchas multiplicaciones las necesarias se hace lo inverso, se define cuantos ciclos se necesita por activacion.\n",
    "neuron_offset = 16\n",
    "neuron = 0\n",
    "layer_outputs = outputs[16]\n",
    "cycles_per_neuron = 3\n",
    "while True:\n",
    "    cycles = cycles + cycles_per_neuron\n",
    "    out = layer_outputs[0,neuron]\n",
    "    write_conv_output(out, neuron*neuron_offset, IOBuffer_2)\n",
    "    neuron = neuron + 1\n",
    "    buffer_stadistics(IOBuffer_2,stats_IOBuffer_2,cycles_per_neuron)\n",
    "    if neuron == 120:\n",
    "        break\n",
    "print(\"Ciclos procesados:\",cycles)\n",
    "print(\"Capa FC\")\n",
    "neuron_offset = 16\n",
    "neuron = 0\n",
    "layer_outputs = outputs[20]\n",
    "neurons_per_cycle = 2\n",
    "while True:\n",
    "    cycles = cycles + 1\n",
    "    counter = 0\n",
    "    while True:\n",
    "        out = layer_outputs[0,neuron]\n",
    "        write_conv_output(out, neuron*neuron_offset, IOBuffer_1)\n",
    "        neuron = neuron + 1\n",
    "        counter = counter + 1\n",
    "        if counter == neurons_per_cycle or neuron == 84:\n",
    "            break\n",
    "    buffer_stadistics(IOBuffer_1,stats_IOBuffer_1,1)\n",
    "    if neuron == 84:\n",
    "        break\n",
    "print(\"Ciclos procesados:\",cycles)\n",
    "print(\"Capa FC\")\n",
    "neuron_offset = 16\n",
    "neuron = 0\n",
    "layer_outputs = outputs[24]\n",
    "neurons_per_cycle = 3\n",
    "while True:\n",
    "    cycles = cycles + 1\n",
    "    counter = 0\n",
    "    while True:\n",
    "        out = layer_outputs[0,neuron]\n",
    "        write_conv_output(out, neuron*neuron_offset, IOBuffer_2)\n",
    "        neuron = neuron + 1\n",
    "        counter = counter + 1\n",
    "        if counter == neurons_per_cycle or neuron == 10:\n",
    "            break\n",
    "    buffer_stadistics(IOBuffer_2,stats_IOBuffer_2,1)\n",
    "    if neuron == 10:\n",
    "        break\n",
    "print(\"Ciclos procesados:\",cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
