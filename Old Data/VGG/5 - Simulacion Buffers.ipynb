{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from fxpmath import Fxp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_current = os.path.abspath('')\n",
    "dir_parent  = os.path.dirname(dir_current)\n",
    "if not dir_parent in sys.path: sys.path.append(dir_parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametros de Simulacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parametros de Cuantizacion\n",
    "bits_activaciones      = 12\n",
    "precision_activaciones = 6\n",
    "bits_pesos_conv        = 12\n",
    "precision_pesos_conv   = 8\n",
    "bits_pesos_fc          = 6\n",
    "precision_pesos_fc     = 6\n",
    "\n",
    "# Parametros de buffer input/output\n",
    "Malpc = 12    #Maximo de activaciones leidas en un ciclo\n",
    "Maepc = 12    #Maximo de activaciones escritas en un ciclo\n",
    "bits_lectura_input    = Malpc*bits_activaciones\n",
    "bits_escritura_output = Maepc*bits_activaciones\n",
    "\n",
    "#Parametros de la matriz de dsp slices.\n",
    "filas      = Malpc\n",
    "dsp_slices = 720\n",
    "columnas   = dsp_slices/filas\n",
    "\n",
    "#Parametros de Buffers de pesos\n",
    "Mpclpc = 24   # Maximo de pesos convolucionales leidos en un ciclo\n",
    "Mpflpc = 48   # Maximo de pesos full conectados leidos en un ciclo\n",
    "bits_lectura_pesos_conv  = Mpclpc*bits_pesos_conv\n",
    "bits_lectura_pesos_fc    = Mpflpc*bits_pesos_fc\n",
    "\n",
    "#Tama√±o del buffer\n",
    "IOBuffer_size = 3211264*bits_activaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga del modelo y sus pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import VGG16_body\n",
    "from models import Weight_Quantization\n",
    "\n",
    "# Creacion de la red\n",
    "Nclasses = 9\n",
    "\n",
    "Qinput_layer  = tf.keras.Input((224,224,3))\n",
    "Qoutput_layer = VGG16_body(Qinput_layer, Quantization = True, word_size = bits_activaciones, frac_size = precision_activaciones, N_labels = Nclasses)\n",
    "QVGG16 = tf.keras.Model(inputs=Qinput_layer, outputs=Qoutput_layer)\n",
    "\n",
    "# Carga de los pesos\n",
    "cwd = os.getcwd()\n",
    "Wgt_dir = os.path.join(cwd,'TrainedWeights')\n",
    "Wgt_dir = os.path.join(Wgt_dir,'WeedWeights')\n",
    "Wgt_dir = os.path.join(Wgt_dir,'Weights')\n",
    "QVGG16.load_weights(Wgt_dir)\n",
    "\n",
    "# Cuantizacion de los pesos\n",
    "Weight_Quantization(model = QVGG16, \n",
    "                    Frac_Bits = precision_pesos_conv, Int_Bits = (bits_pesos_conv-precision_pesos_conv-1),\n",
    "                    Dense_Frac_Bits = precision_pesos_fc, Dense_Int_Bits = (bits_pesos_fc-precision_pesos_fc-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Quantization_layer\n",
    "from functions import VGG_resize_v2\n",
    "\n",
    "x_test,  _  = tfds.as_numpy(tfds.load('deep_weeds', split='train[85%:86%]', batch_size=-1, as_supervised=True))\n",
    "del _\n",
    "# Normalizacion\n",
    "x_test = x_test[0:30]\n",
    "x_test = x_test/255.\n",
    "# Cuantizacion\n",
    "x_test = Quantization_layer(x_test)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(x_test)\n",
    "test_dataset = test_dataset.map(VGG_resize_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para correr la simulacion remotamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import get_all_outputs\n",
    "def get_Batch_outputs(model, iterator, List_of_layers):\n",
    "    List  = []\n",
    "    image = next(iterator,None)\n",
    "    while image != None:\n",
    "        Outputs = get_all_outputs(model, tf.expand_dims(image,axis=0))\n",
    "        Outputs = [Outputs[i] for i in List_of_layers]\n",
    "        List.append(Outputs)\n",
    "        image = next(iterator,None)\n",
    "    return List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "LayerList = [1,3,5,7,9,10,12,14,16,18,19,21,23,25,27,29,31,32,34,36,38,40,42,44,45,47,49,51,53,55,57,58,61,63,65,67,69,71]\n",
    "iterator  = iter(test_dataset)\n",
    "ActList   = get_Batch_outputs(QVGG16, iterator, LayerList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inicia simulacion\n",
      "Capa Convolucional\n",
      "tiempo transcurrido: 17713.968396663666 ciclos: 309016\n",
      "Capa Convolucional\n",
      "tiempo transcurrido: 39515.74285316467 ciclos: 3606735\n",
      "Capa MaxPooling\n",
      "tiempo transcurrido: 50622.528431892395 ciclos: 3678415\n",
      "Capa Convolucional\n",
      "tiempo transcurrido: 66777.32387661934 ciclos: 5210512\n",
      "Capa Convolucional\n",
      "tiempo transcurrido: 86304.19273376465 ciclos: 8274769\n",
      "Capa MaxPooling\n",
      "tiempo transcurrido: 90359.7020213604 ciclos: 8310609\n",
      "Capa Convolucional\n",
      "tiempo transcurrido: 98319.44616127014 ciclos: 9758239\n",
      "Capa Convolucional\n",
      "tiempo transcurrido: 105659.11774849892 ciclos: 12653549\n",
      "Capa Convolucional\n",
      "tiempo transcurrido: 113487.66587257385 ciclos: 15548859\n",
      "Capa MaxPooling\n",
      "tiempo transcurrido: 115621.49722123146 ciclos: 15570363\n",
      "Capa Convolucional\n",
      "tiempo transcurrido: 120349.53251171112 ciclos: 17367416\n",
      "Capa Convolucional\n",
      "tiempo transcurrido: 125467.5360686779 ciclos: 20961589\n",
      "Capa Convolucional\n",
      "tiempo transcurrido: 131505.03171944618 ciclos: 24555762\n",
      "Capa MaxPooling\n",
      "tiempo transcurrido: 133079.35372543335 ciclos: 24570098\n",
      "Capa Convolucional\n",
      "tiempo transcurrido: 135033.51668596268 ciclos: 25848009\n",
      "Capa Convolucional\n",
      "tiempo transcurrido: 136855.00380516052 ciclos: 27125920\n",
      "Capa Convolucional\n",
      "tiempo transcurrido: 138994.02685546875 ciclos: 28403831\n",
      "Capa MaxPooling\n",
      "tiempo transcurrido: 139417.07124471664 ciclos: 28407415\n",
      "Capa Full Conectada\n",
      "tiempo transcurrido: 139467.08129239082 ciclos: 29122537\n",
      "Capa Full Conectada\n",
      "tiempo transcurrido: 139515.37272524834 ciclos: 29239501\n",
      "Capa Full Conectada\n",
      "imagenes procesadas: 1  tiempo: 139638.96738171577 ciclos:  29239843\n",
      "Tiempo de simulacion: 139638.97641181946\n"
     ]
    }
   ],
   "source": [
    "# Bufferes\n",
    "IOBuffer_1 = np.zeros(IOBuffer_size,dtype=int)\n",
    "IOBuffer_2 = np.zeros(IOBuffer_size,dtype=int)\n",
    "\n",
    "# Diccionario de estadisticas de los buffers\n",
    "stats_IOBuffer_1 = {\"ultimo_valor\"    : np.zeros(IOBuffer_size,dtype=int),\n",
    "                    \"ciclos_1\"        : np.zeros(IOBuffer_size,dtype=int),\n",
    "                    \"cambios_logicos\" :np.zeros(IOBuffer_size,dtype=int)}\n",
    "stats_IOBuffer_2 = {\"ultimo_valor\"    : np.zeros(IOBuffer_size,dtype=int),\n",
    "                    \"ciclos_1\"        : np.zeros(IOBuffer_size,dtype=int),\n",
    "                    \"cambios_logicos\" :np.zeros(IOBuffer_size,dtype=int)}\n",
    "\n",
    "import simulation\n",
    "import time\n",
    "from functions import save_obj, load_obj, Load_Image\n",
    "\n",
    "# Variables de simulacion\n",
    "simulation.Malpc            = Malpc\n",
    "simulation.Maepc            = Maepc\n",
    "simulation.Mpclpc           = Mpclpc\n",
    "simulation.Mpflpc           = Mpflpc\n",
    "simulation.filas            = filas\n",
    "simulation.columnas         = columnas\n",
    "simulation.Word_bits        = bits_activaciones\n",
    "simulation.Frac_bits        = precision_activaciones\n",
    "simulation.QVGG16           = QVGG16\n",
    "simulation.IOBuffer_1       = IOBuffer_1\n",
    "simulation.stats_IOBuffer_1 = stats_IOBuffer_1\n",
    "simulation.IOBuffer_2       = IOBuffer_2\n",
    "simulation.stats_IOBuffer_2 = stats_IOBuffer_2\n",
    "\n",
    "\n",
    "iterator   = iter(test_dataset)\n",
    "ciclos     = 0\n",
    "index      = 0\n",
    "batch_size = 1\n",
    "t = time.time()\n",
    "while index < batch_size:\n",
    "    image = next(iterator)\n",
    "    Load_Image(IOBuffer_1,image, Word_bits = bits_activaciones, Frac_bits = precision_activaciones)\n",
    "    ciclos += simulation.VGG16_Simulation_b(image)\n",
    "    save_obj(stats_IOBuffer_1,'stats_B1')\n",
    "    save_obj(stats_IOBuffer_2,'stats_B2')\n",
    "    index = index + 1\n",
    "    print('imagenes procesadas:',index,' tiempo:',time.time()-t,'ciclos: ',ciclos)\n",
    "print('Tiempo de simulacion:',time.time()-t)\n",
    "save_obj(ciclos,'numero_de_ciclos')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
